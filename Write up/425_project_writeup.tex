% personal latex template

% vegito2002@gmail.com
\documentclass{article}
\usepackage{times}
\usepackage{mathptmx}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage[letterpaper, margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{lipsum}
\usepackage{courier}
% \usepackage{tabularx}
\usepackage[export]{adjustbox}
% \usepackage[landscape]{pdfpages}
\usepackage{enumitem}
\usepackage{spreadtab}
% \usepackage{enumerate}


\graphicspath{ {images/} }

\usepackage[dvipsnames]{xcolor}  %% Allow color names
\lstset
{ %Formatting for code in appendix
  belowcaptionskip=1\baselineskip,
  xleftmargin=\parindent,
  language=Java,   %% Change this to whatever you write in
  breaklines=true, %% Wrap long lines
  basicstyle=\ttfamily,
  % numbers=left,
  % stepnumber=1,
  commentstyle=\itshape\color{Gray},
  stringstyle=\color{Orange},
  keywordstyle=\bfseries\color{WildStrawberry},
  identifierstyle=\color{Blue},
}
\usepackage{titlesec}
\usepackage{amssymb}
\newenvironment{claim}[1]{\par\noindent\underline{Claim:}\space#1}{}
\newenvironment{claimproof}[1]{\par\noindent\underline{Proof:}\space#1}{\leavevmode\unskip\penalty9999 \hbox{}\nobreak\hfill\quad\hbox{$\blacksquare$}}

\setcounter{secnumdepth}{4}

\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\begin{document}

% Article top matter
\title{\textsc{EN 600.425 Declarative Methods \\ - Term Project Writeup}\\ \textbf{\textsc{Better } \texttt{diff}}} %\LaTeX is a macro for printing the Latex logo
\author{Guoye Zhang, Qiang Zhang\\
        % \texttt{Hopkins ID: 92CC3E}
        }  %\texttt formats the text to a typewriter style font
\date{\today}  %\today is replaced with the current date
\maketitle

\section{Introduction}
The utility \texttt{diff} is commonly used in all scenarios, whether for programming purpose or in general text editing circumstances. The website Github integrated \texttt{diff} into their version control system, facilitating ubiquitous knowledge of the utility. This legacy utility is based on the renowned \textit{Edit Distance} algorithm, which in essence is a Dynamic Programming algorithm. \\

Aside from the application domain of version control, \texttt{diff}'s algorithm in itself is interesting and instructive enough for most computer science students to delve into. In general sense, the concepts of finding similar text and displaying minimum edit distance can be embodied in various domains and categories of applications. Our project aims at extending \texttt{diff} to provide firstly the feature of multi-file editting source referencing, accompanied with visualization, that can display the chain of editting among more than two files placed in the same folder, together with a better algorithm that fixes a certain scenario where the normal \texttt{diff}'s Edit Distance algorithm would perform suboptimally, which is a case we already described in the proposal.\\

\subsection{Algorithmic Optimization}
As a reminder, recall the scenario where normal \texttt{diff} would perform suboptimally. In this code snippet:\\
\begin{lstlisting}
   for(int i=0; i<10; i++) {
       System.out.println("First line");
   }
   for(int i=0; i<10; i++) {
       System.out.println("Second line");
   }
   for(int i=0; i<10; i++) {
       System.out.println("Third line");
   }
\end{lstlisting}
from which we will delete the second \texttt{for} block. And if we use the traditional \texttt{diff} on the old and new versions of this snippet, we would get:\\
\begin{lstlisting}
   for(int i=0; i<10; i++) {
       System.out.println("First line");
   }
   for(int i=0; i<10; i++) {
 -     System.out.println("Second line");
 - }
 - for(int i=0; i<10; i++) {
       System.out.println("Third line");
   }
\end{lstlisting}
Instead of what would be expecting as follows:
\begin{lstlisting}
   for(int i=0; i<10; i++) {
       System.out.println("First line");
   }
 - for(int i=0; i<10; i++) {
 -     System.out.println("Second line");
 - }
   for(int i=0; i<10; i++) {
       System.out.println("Third line");
   }
\end{lstlisting}
This case is fixd with our improved version of \texttt{diff} algorithm, which we shall call by \texttt{MDiff} in the rest of this document. In fact, there are much more scenarios where the traditional \texttt{diff} algorithm would disappoint you. For example, consider the instance of comparison below (results are hand-generalized from Github's webpage highlighting):
\begin{lstlisting}
<a><b>
 ----

<b><a>
 ++++
\end{lstlisting}
The notations used here should be self-explanatory. When comparing the two strings of \texttt{<a><b>} and \texttt{<b><a>}, traditional \texttt{diff} would return the results as shown above, which means, in a 0-based indexing convention, deleting the 1-4 of the first string, and adding the 4 characters at index 1-4 of the second string. But this answer of editting distance is clearly suboptimal. The optimal solution we expect would be:
\begin{lstlisting}
<a><b>
 -  -

<b><a>
 +  +
\end{lstlisting}
which is the answer that \texttt{MDiff} would return.

\subsection{Multi-file Referencing}
In this part, we extended \texttt{diff} to another domain of applicaiton of interest. To most eyes, \texttt{diff} is generally used to comparing the editting distance between two files. It is a utility used widely in use. Indeed, it is a utility, in that it does a job well, but it is not typically tailored for any domain. We implemented an application that embodies \texttt{MDiff} in its core, but meanwhile provides far more convenient and appleasing functionalities. \\

For oft, we are interested not only to know the difference between two text files. Rather, we want to be able to look at some paragraph of this text file, and find out from which other paragraph in other file this paragraph derives. Text reusing is so common nowadays that this is a feature of no trivial productivity significance. In fact, to fullfill such a task, of finding the predecessor of a paragraph in this text file, most people would resort to nothing better than a brute-force file-by-file \textit{Open\&Search} routine. \\

To implement this feature, the optimized algorithm of \texttt{MDiff} alone is not quite enough. In practical scale, even comparing only two files with a \texttt{diff}-based algorithm can be undesirably slow. Not to mention that we are trying to determine edit chains between multiple files. For the application to be fast enough to be useful in practice, certain techniques are used to structure the implementation of its functionality.\\

The use case we are trying to address here is a scenario where the folder contains, rather than multiple files, multiple versions of a file. For example, \texttt{file1} could be the original file of an article in craft. Then after certain modifications, \texttt{file2} results. In the end, the folder contains multiple files, each pair of which, albeit being different, shares an overall similarity larger than 50\%. Aside from that, we make the below assumptions:
\begin{enumerate}
  \item File name indicate each file's last-modified-by time in an increasing order. Thus if there is a file $i$ and a file $j$ with $i<j$, we can convince ourselves that file $i$ is lastly modified earlier than file $j$ and file $j$ is thus possile a successor of $i$: meaning we should include file $i$'s texts when we try to search for the predecessor of any text paragraph in file $j$. To be honest, this modelling is not perfectly accurate. For example, in the case below:\\
  \includegraphics[scale=0.3,center]{pic1.png}

  File 5 is modified later than file 4 (since 5 is larger than 4, and thus file 5 has a later last modification timestamp), but file 5 actually should not consider file 4 as one of its predecessor, because file 5 comes from modifications of file 2, and is on a editting path branch disjoint from that of file 2. 

  But overall, our approach should work fine. 
  \item The author of the files knows to seperate each section, or paragraph of his files by an empty line. Like:
  \begin{lstlisting}
  <paragraph1>

  <paragraph2>

  <paragraph3>
  \end{lstlisting}
  This is similar to how most Latex users format their documents. 
\end{enumerate}
When we open a certain file $i$, we want to be able to know:
\begin{enumerate}
  \item \textbf{Objective 1}: Amongst all the paragraphs of all files in this folder, which paragraph is most likely to be the direct predecessor of this paragraph? Or, which paragraph is most likely to be the direct source of modification for this paragraph?
  \item \textbf{Objective 2}: After finding the most likely predecessor of this paragraph, what are the minimum amount of edits required to change from the predecessor paragraph to the paragraph under inspection?
\end{enumerate}

Objective 2 as we described in the last subsection, is addressed by an optimized version of \texttt{diff} algorithm, which we call \texttt{MDiff}. Objective 1's on the other hand, is key to speeding up the application to a speed suitable for real-life utilization. \\

By matching texts in the unit of paragraph first, we largely reduced the computational effort required. Yet this scheme does not violate any practical editting convention to render the application infutile. Normally, when a user edits a file, the edits, however many there are at a time, can be each bucketted into its own paragraph. By matching paragraphs first, we limit the scope to apply \texttt{MDiff} on to only a paragraph a time.  This is analogous to an idea in 3D game designing that you don't have to render the entire 3D scene and maintain it at all time. You just have to render as large as the player's camera can capture and only when the camera does captures it. This optimization can reduce the computational cost of the application by a factor as large as several hundreds inpractice. \\

The key idea behind implementing Objective 1, and the paragraph matching explained above, is determine textual similarities. There is a well-established technique called Min-hash which is used to calculate a text document's signature, which can in turn be used to compare with another document's signature to determine the similarity between the two documents. Of course, we here are looking at the similarity between two documents rather than two paragraphs. We used a third-party library \cite{minhash} which can return the similarity of two text strings based on the Min-hash algorithm. \\

There are more subtlties to be clarified in this scheme. But we are leaving further elaboration for later part of this document. 

\subsection{Running Instruction}
By this point, enough information is provided to understand what this project hopes to deliver. In this section, we provide step by step instructions so that you can run the application now and see the results before going further. More elaborations follows.

\section{First Step: Predecessor Matching}
Definition first: \textbf{Predecessor Matching} refers to the process of finding, for each paragraph $p$ in each file $file_p$, amongst all the paragraphs that are contained in files with a lastly modification timestamp (which is assumed to be indicated by the filename number's value ordering) smaller than $file_p$. The concept of similarity is calculated by comparison of signature which is calculated by \textbf{Minhash}.
\subsection{Modelling}
As described in the previous section, our first goal is to be able to inspect a certain file $i$ in the folder, and immediately locate the most similar paragraph amongst all files in the folder, under assumptions:
\begin{enumerate}
  \item File name indicate each file's last-modified-by time in an increasing order.
  \item The author of the files knows to seperate each section, or paragraph of his files by an empty line. 
\end{enumerate}

The second assumption is established so that there is a valid way to define the notion of ancestry. If we treat an entire document as one single paragraph, then there is no point in saying \textit{finding the predecessor of this entire document}. Because in practice, most modifications between files are minor and of comparable degree, which means different successors of the same predecessor document may end up looking very much alike. Even though we devise an algorithm to locate such an predecessor document for the document being inspected, the output is most likely to be inaccurate and uninformative. \\

After dividing a document into paragraphs, the notion of ancestry and the concept of reusing now makes sense. Think it this way: when you write code, if you say \textit{reuse}, you usually refers to reusing a part of a code file, usually a function, or block. But in the case you want to reuse the code file in its entirety, you just \texttt{import} or \texttt{include} it. Such file-wise reusing operations would normally indicate the source of reusing directly and an dedicated algorithm to solve the ancestry relationship would be unnecessary. The same analysis applies to the case of general text files. We are only interested in finding the predecessor of a snippet of a text file, which is a reused part. We conveniently define such a concept of reused part as a paragraph. There can be other choices of delimitation of reused parts, but obsession over this definition is moot per se. \\

Now, to find the most likely predecessor of a paragraph, is to find a paragraph that:
\begin{enumerate}
  \item is contained in a file that is lastly modified earlier than the file that contains the paragraph under inspection.
  \item shares, amongst all paragraphs that satisfies the previous condition, a highest similarity with the paragraph under inspection.
  \item owns a similarity with the paragraph that satisfies the previous condition that is higher than a lower threshold.
\end{enumerate}
And to find such a paragraph that satisfies the above three conditions, we use the theory of textual similarity. \\

\subsection{Texutual Similarity and Textual Similarity}
Since this is only a subroutine we resort to in this project, rather than the project itself's primary focus, the introduction here is brief. Minhash is a hashing scheme that can hash each string or piece of text to a value that is necessarily short but informative enough to capture the uniqueness of the text. This value is called the \texttt{signagure} of this text. Minhash is designed to be able to hash similar texts to similar signatures. And by a corresponding comparison function of two texts' respective signature, the two texts' similarity can be determined.

\subsection{Implementation}
Back to the implementation of the application. In particular, we implement the process as follows:
\begin{enumerate}
  \item Read in all files in the folder in the order of increasing lastly-modification time, which is determined by the filenames. Create two string arrays, one to store the filenames of all the files in question and one to store each file's content of all files. 
  \item For each content string of the file content array, break up the content string into an string array of storing this file's lines. By doing this, we have a 2-dimensional array of \texttt{filelines[m][n]} where \texttt{m} stands for the number of files involved, and \texttt{n} stands for each file's number of lines in its content. Incidentally, we trim out the whitespaces at the head and tail of each line. 
  \item Using this 2-dimensional array \texttt{filelines[m][n]}, we scan all the lines of all files in the order of an intuitive 2-dimensional iterative order: 
  \begin{lstlisting}
  for (int i = 1 .. m) {
    for (int j = 1 .. n) {
      <process>
    }
  }
  \end{lstlisting}
  In this scanning, we break up all the lines into paragraphs by the delimiter of \textit{emptyline} as mentioned before. For each paragraph, we iterate through all paragraphs discovered before it, and find the one paragraph with the highest similarity to it, which has to be above 80\%. We determine this paragraph as the \textbf{predecessor} of current iteration's paragraph. Relevant information are all stored. 
  \item Once we know the predecessor for each of all paragraphs of all files in the folder, we also maintain the edit distance produced by the improved \texttt{MDiff} algorithm with each paragraph. More specifically, this edit distance is calculated against each paragraph's predecessor with itself. By now, we have all the information we need to implement the application layer features in the future. For each paragraph, the information, in summary, typically consists of:
  \begin{itemize}
    \item The filename of the file that contains this paragraph. Note that we are being a little simplistic here: we assume that each file has a filename in the format of $i.<extension>\ \forall i$. This assumption does not harm the generality of application for the project and can be easily extended if necessary.
    \item The start and ending line numbers of this paragraph in the file that contains it. With these line numbers and the filename stored in the above entry, the paragraph itself now can be uniquely located.
    \item A pointer to the paragraph's \textbf{predecessor}, which is determined by a concept of \textit{maximum similarity so far} as described above.
    \item Annotation to represent the result of running \texttt{MDiff} with this paragraph's predecessor as the first argument and this paragraph itself as the second argument. Note that although we are trying to accomplish something that looks like multi-file \texttt{diff}ing here, the \texttt{MDiff} algorithm itself only takes two strings at a time. 

    The annotation consists of three parts. We will illustrate each part's meaning with this example's help:
    \begin{lstlisting}
<a><b>
 -  -

<b><a>
 +  +
    \end{lstlisting}
    \begin{itemize}
      \item The \texttt{boolean same} value, which is \texttt{true} if the two string arguments are the same, which means the edit distance is 0. In the case of the example shown here, this flag should be \texttt{false}.
      \item The \texttt{boolean[] delete} flag array. The explanation is left to below.
      \item The \texttt{boolean[] add} flag array. Remind yourself that although we are introducing the information maintained for each paragraph, the \texttt{delete} and \texttt{add} flag arrays actually apply to this paragraph's predecessor and this paragraph itself. Since for each paragraph, its predecessor can be uniquely identified.

      The \texttt{delete} boolean flag array corresponds to the predecessor string, which is \texttt{<a><b>} in this case. The flags in this array indicates whether each character in the string would be kept so that the predecessor string could be editted into the target successor string with minimum editting distance. In particular, each flag is false if the corresponding character in this paragraph's predecessor paragraph should be deleted in min-distance editting. In this case, the \texttt{delete} array should be \texttt{\{true,false,true,true,false,true\}}. Note that this information is stored with the paragraph \texttt{<b><a>}, rather than the paragraph (string) \texttt{<a><b>}.

      Similarly, \texttt{add} boolean flag array corresponds to the new, or successor string/paragraph of the pair. If \texttt{add[i]} is true, then the character at 0-based position $i$ will be be seen as an uneditted character(certainly not deleted, yet is not also added to the new paragraph) when trying to edit this paragraph's predecessor into this paragraph itself with minimum distance. If \texttt{add[i]} is false, then the character at position $i$ will be considered newly added during the min-distance editting. In this example, the \texttt{add} array, of a value \texttt{\{true,false,true,true,false,true\}}, should be maintained with the paragraph \texttt{<b><a>}.
    \end{itemize}
  \end{itemize}
\end{enumerate}

This section is intended to focus on matching each paragraph with its predecessor, which is located by the \textit{most similar paragraph so far} scheme as decribed above. In the explanation, we assumed that we already have the utility of \texttt{MDiff} and includes its result for each paragraph together with the result of \textbf{Predecessor Matching}. Note that with these information stored, we can easily implement any visualization we want. We did implement a HTML-based visualization, but discussion shall be omitted. \\

Although this section is named the \textbf{First Step}, we essentially introduced the big picture architecture of the project. With the skeleton built out, all that left is to fill in the muscles, especially a powerful one. The \textbf{Predecessor Matching} scheme based on \textbf{Minhash} provides all the inter-paragraph information we need. To get the intra-paragraph information, we need an algorithm to compare a paragraph itself to its predecessor paragraph. And the introduction of this algorithm is developed next.

\section{Better \texttt{diff}: \texttt{MDiff}}
Our optimization of the original \texttt{diff}, or Edit Distance algorithm, focuses on fixing Edit Distance algorism's ignorance of \textbf{brackets pairing}. Note that although we use the term \textit{brackets} here, we actually refer to parentheses, brackets, braces in general. This naming convention would apply for the rest of this document. \\

In section 1 of \textit{Introduction}, we gave several examples where Edit Distance algorithm won't be able to find an optimal, or even reasonable result. In our improved algorithm of \texttt{MDiff}, we are able to deal with not only ignorance of brackets pairing, which in practice usually comes in the form of an editting that deleted or added only part of a paring of brackets, but also Edit Distance's ignorance of quote pairing. Special scenarios like escaping character are also considered.

\subsection{Failed Attemp 1 with ZIMPL}
This problem appears to us in the beginning as difficult to solve with Dynamic Programming which is adopted by the original Edit Distance algorithm. We decided to put what we learned in this course in practice and give ZIMPL a try. \\

The files associated with this attempt are all put in the folder \textit{Deprecated} which is located at the root level:
\begin{itemize}
  \item \texttt{Script.java} is a trivial Java file to write input \texttt{txt} files for the program. \texttt{out.txt} is the temporary file of the Java file's output.
  \item \texttt{old.txt} and \texttt{new.txt} are files to represent the old string and new string as the input of the program. Instead of expressing the inputs as a string, we expressed them as an array of integers. The encoding and decoding between should be straightforward.
  \item \texttt{zimpl\_attemp1.zpl} is the program file. I would not recommend running it since it unfinished and erroneous in nature. 
\end{itemize}

The approach we took in this attempt is to encode each input string's each character as an integer. Then we try to use ZIMPL to decide a binary variable for such a digit. This binary variable plays a role similar to each \texttt{delete} and \texttt{add} boolean flag we used in the java program. \\

The process should be easier to explain with an example. Note that in this attempt we have not come so far to addressing the ignorance of bracket pairing yet. Implementing Edit Distance alone seems difficult enough. With this simple example, we begin the discussion:
\begin{lstlisting}
Old String:
#index, number
1,1
2,2
3,3
4,4
5,5

New String:
#index, number
1,1
2,2
3,4
4,3
5,5
\end{lstlisting}
The input string is stored in variables \texttt{old[M]} and the output string is stored in variables \texttt{new[N]}. For \texttt{M}, we also have the binary annotation variable \texttt{delete[M]}, and similarly \texttt{add[N]} for \texttt{N}. Note that the value of the binary variables are the opposite of the \texttt{delete} and \texttt{add} Java boolean flags mentioned above. Here, \texttt{delete[m]} is 1 iff the digit $m$ of the input string (digit array) should be deleted in a min-distance editting. Similarly, i\texttt{add[n]} should be 1 iff the digit $n$ should be seen as an added digit in a min-distance editting. \\

With such definition, we derive another two variable definitions: \texttt{after\_delete[M]} and \texttt{before\_add[N]}.  \texttt{after\_delete[M]} is essentially \texttt{old[M]} after a mapping function being applied, which sets \texttt{after\_delete[m]} to 0 if \texttt{delete[m]} is 1 and to \texttt{old[m]} otherwise. \texttt{before\_add[N]} is defined in a similar way. It is intuitive to add a minimizing objective function, where the coefficients of \texttt{delete[M]} and \texttt{add[N]} are all positive. All that's left to now is to set up constraints. \\

Note, to express that the editting determined by \texttt{delete[M]} and \texttt{add[N]} is a valid editting, which measn applying the indicated editting would correctly tranform \texttt{old[M]} to \texttt{new[N]}. Such a notion of valid editting shall be implemented with a constraint, which we might as well call \textbf{mapped equality} that could determine the following two strings equal (these two strings do conform to the example inputs listed above):
\begin{lstlisting}
after_delete[M]:
1,2,0,4,5

before_add[N]
1,2,4,0,5
\end{lstlisting}
We first considered removing zeroes, which shortly turned out infeasible if we have a general case of \texttt{1,2,0,0,0,0,0,3,4} to process. We can't express the idea of a while-loop in ZIMPL, and it is infeasible to remove consecutive zeroes of arbitrary length. \\

Even more, at this point, we realized that trying to further transforming \texttt{after\_delete[M]} and \texttt{before\_add[N]} is very hard. We then turned our mind to tuning the objective function with some soft constraints to lure the solver to the correct solution. These attempts all failed with some input cases so I will just briefly summarize here:
\begin{itemize}
  \item Objective function: the terms
  \begin{lstlisting}
  sum <m> in M: delete[m] + sum <n> in N: add[n]
  \end{lstlisting}
   are fixed in all the approaches below. 
  \item Hard constraint: sum of \texttt{after\_delete[M]}  and \texttt{before\_add[N]} should be equal. This is only a necessary constraint to express the mapped equality, but not enough to be sufficient.
  \item Hard constraint: the number of zeroes in each of \texttt{after\_delete[M]} and \texttt{before\_add[N]} is the same. Again, this is also only a necessary constraint. \\

  And the below appraoches are mostly inspired by analysis of concret input cases:
  \begin{itemize}
    \item Approach 1: adding 
    \begin{lstlisting}
    - vabs(sum <m> in M: after_delete[m] * m - sum <n> in N: before_add[n] * n) / 2
    \end{lstlisting}
     to the objective function. However we tune the weight of this term, the solver would always be too eager to increase the number of deletions and additions to maximize its gain on this term.
    \item Approach 2: derive \texttt{difference1[M]} for \texttt{after\_delete[M]} with \texttt{difference1[m]} standing for \texttt{after\_delete[m-1]} minus \texttt{after\_delete[m]}. \texttt{difference2[N]} is defined similarly based on \texttt{before\_add[N]}. Then we require that:
    \begin{lstlisting}
vabs(difference1[m]) == sum <n> in N: vabs(difference2[n])
    \end{lstlisting}
    We did know this constraint can't be enough. Though seems tempting, the solver, for various input cases, ends up finding clever roundabouts satisfying this constraint. 
    \item Approach 3: \texttt{difference} variables defined as above. But now we add 
    \begin{lstlisting}
+ vabs(sum <m> in M: vabs(difference1[m])*m - sum <n> in N: vabs(difference2[n])*n)
    \end{lstlisting}
    To the objective function.
  \end{itemize}
  Other trivial approaches are tried out as well, and do not merit mentioning here. 
\end{itemize}


\subsection{Suboptimal Attemp 2 with ZIMPL}
Upon exploration, we realized that the difficulty of contraint expression mostly comes from the form of encoding we picked. Thus in this attempt, we changed to another approach of encoding the problem. The program associated with this attempt is stored in the \textit{Deprecated} subfolder as \texttt{zimpl\_attemp2.zpl}. \\

This attempt's code is better explaned with an example (note that the explanations here are to be viewed by side of the code. Some settings in the source code are not mentioned here for brevity of expression) :
\begin{lstlisting}
param s1[I2] := <1>10,<2>11,<3>12,<4>10,<5>13,<6>12 default 0;
param s2[I2] := <1>10,<2>11,<3>12,<4>10,<5>14,<6>12,<7>10,<8>13,<9>12 default 0;
\end{lstlisting}
These two sets of parameters refer to the input arrays. Thus, what we have as inputs here are:
\begin{lstlisting}
input1: 10, 11, 12, 10, 13, 12
input2: 10, 11, 12, 10, 14, 12, 10, 13, 12
\end{lstlisting}
The length parameter here is \texttt{l=max\(6,9\)=9}, and correspondingly:
\begin{lstlisting}
set I := {1..9}
set I2 := {1..18}
\end{lstlisting}
Why do we have \texttt{I2}? Because now instead of tranforming each deleted or added digit to 0 explicitly, we implicitly express the edit as a digit not being choosen. Thus to express \texttt{1,2,3,4,5} with 3 deleted in the min-distance editting, we simply express \textit{we only choose digits at indices of \texttt{1,2,4,5,6}}. Note that the 6 here is an out-of-bound, which is 0 by padding. And the existence of \texttt{I2} is exactly for this purpose. As long as we decides to delete some digit in the original legit index bound \texttt{I}, we express it as omitting the deleted digit's index, and adding alternatively another out-of-bound index in the padding region filled with 0s. Remind yourself that, adding in the second argument string can be viewed the same way as deleting a digit in the first argument string. This is illustrated before when we introduced the Java boolean flag arrays \texttt{delte} and \texttt{add}.\\

We first have variables \texttt{in1[I]} and \texttt{in2[I]}. Taking \texttt{in1[I]} as an example. \texttt{in1[1]} referes to the fact that the digit 1 is not affected (deleted) in the min-distance editting. All other \texttt{in1} and \texttt{in2} variables are defined similarly. Back to our example, we should have:
\begin{lstlisting}
input1: 10, 11, 12, 10, 13, 12
in1:     1,  2,  3,  4,  5,  6
input2: 10, 11, 12, 10, 14, 12, 10, 13, 12
in2:     1,  2,  3,  7,  8,  9, 10, 11, 12 
\end{lstlisting}
The digits at indices 4, 5 and 6 are deleted in the optimal solution, so \texttt{in2[4],in2[5],in2[6]} points to consecutive positions after the 3 deleted digits (technically they are "added" digits in the second argument string, but again, adding in the second argument can also be viewd the same way as deletion in the first argument string). \\

With this sorted out, other variables are either somewhat repetitive or self-explanatory. \texttt{c1[I]} and \texttt{c2[I]} refers to the picked digits as instructed by \texttt{in1} and \texttt{in2}:
\begin{lstlisting}
input1: 10, 11, 12, 10, 13, 12
in1:     1,  2,  3,  4,  5,  6
c1:     10, 11, 12, 10, 13, 12
input2: 10, 11, 12, 10, 14, 12, 10, 13, 12
in2:     1,  2,  3,  7,  8,  9, 10, 11, 12 
c2:     10, 11, 12, 10, 13, 12,  0,  0,  0
\end{lstlisting}
Note that the last three zeros of \texttt{c2} come from the out-of-bound padding area after \texttt{input2}. \\

The explanations for constraints and objective functions are thus omitted for brevity. In essence, the trick this attempt adopts is using index to filter out digits that would otherwise be 0s that come from editting transformations. The zero digits in attempt 1 is hard to deal with because they can appear at arbitray positions with arbitray consecutive lengths. The trick here, using auxiliary index variables and padding, implicitly picked out all the digits, which would be non-zero in attempt1, together in a consecutive manner. \\

Despite being educative in nature, this program does not perform good enough in practice. Two input strings of maximum length 9 resolved into 3332 variables and 4718 constraints and turns out to be requiring 3 seconds to solve already (with adequate hardware and latest version of solver). Imaging dealing with paragraphs across lines. \\

To this point, we are pretty much sure about the unlikeliness of solving the problem with ZIMPL. Thus starting from next attempt, we went back to good o'l Dynamic Programming. The hope is to add modifications so that Dynamic Programming can address the pairing problem explicitly.

\subsection{Suboptimal Attempt 3 with Backward-Chaining Dynamic Programming}
We started by analyzing where the ordinary Edit Distance algorithm started to went astray. Consider this example:
\begin{lstlisting}
<a><b><c>
  ---
<a><c>
\end{lstlisting}
If running in a Backward-Chaining, or top-down manner, the Edit Distance algorism will produce a result as shown above. The desired result instead is:
\begin{lstlisting}
<a><b><c>
   ---
<a><c>
\end{lstlisting}
The reason for the ED algorism's malfunction is because the tail of \texttt{><c>} are treated as identical in both strings, and thus the algorism only starts considering editting when it comes from the tail of string 1 to the index 5 (0-based) of string 1.\\

A quick fix immediately comes to mind: we can force the algorism to consider dropping \texttt{string1.charAt(6)}, which is a \texttt{>}. At this position, the solver faces a subproblem with both input strings' tail being \texttt{>}, which is a closing bracket. We add one case handling block to the algorism so that the when the algorism seems two input strings with same ending, which is a closing bracket, the algorism will try first dropping the two tails altogether at first, and then try dropping only the longest string's tail. And the algorism compare the two probing's return values. If the latter probing's return value, which results from dropping only the tail of the longer input string, is smaller or equal(which is the case in this example shown above), we choose the latter probing's strategy instead of dropping both tails. \\

This is the major modification added to ED algorism in this attempt, and the program does produce desirable results for quite a lot of test cases, include the original three for-loop cases mentioned in the Introduction section, which terminates in less than 1 second. Note that memoization is implemented in all discussions here and below. \\

But we eventually decided that optimization is not enough. Plus, it is unlikely to be able to address the paring of quotes with this simple optimization.

\subsection{Final Attempt 4 with Forward-Chaining Dynamic Programming}
First, we do a 1-pass iteration of each input string. We store the position of each openning of closing brackets. More specifically, we store each pair of brackets in the form of \texttt{closingIndex -> openingIndex}. We consider the substring between \texttt{openingIndex} and \texttt{closingIndex} to a block enclosed by this pair. \\

Note that there is a subtlety here. Consider this code snippet:
\begin{lstlisting}
<context1>
for (header) {
  body
}
<context2
\end{lstlisting}
In this situation, we have to move the \texttt{openingIndex} of the openning curly brace to the head of its line. This is because we have to always associate each for-loop's header with its body which is a block enclosed by a pair of curly braces. And our later algorism depends on the ability to process each pair-enclosed block as a whole. By moving the opening curly brace's index ahead, we practically included the header inside the block. This prevents the algorithms breaking the atomicity of the header together with the block when processing.\\

Blocks enclosed by quotes are determined in a more subtle way, and the disussions are omitted here. \\

For the rest of discussion to make sense, consider this memoization table for the two input strings of \texttt{[a][c]} and \texttt{[a][b][c]}, respectively denoted as string 1 ad string 2:\\
\includegraphics[scale=0.6,center]{2.pdf}\\

Note what we want to achieve here: in the middle region of this table, we have three paths. Using Forward-Chaining or Backward-Chaining, we would end up choosing either the path on the top or the path in the bottom. But what we really want here, is the path in the middle, which respects the pairing of the brackets. \\

We maintain, aside from a table \texttt{f[][]} as above, which shows the edit distance associated with each subproblem (indexed by the lenghs of the two input argument strings), two other tables:
\begin{lstlisting}
private enum Direction { DIAGONAL, UP, LEFT }
...
Direction[][] prev = new Direction[s1.length + 1][s2.length + 1];
boolean[][] good = new boolean[s1.length + 1][s2.length + 1];
\end{lstlisting}
The first table \texttt{prev}, at each entry \texttt{prev[i][j]} stores how the \texttt{f[i][j]} edit distance is achieved. In particular, there are three ways of reaching at \texttt{[i][j]}:
\begin{itemize}
  \item Moving down from its upstairs neighbor. In the table, if we choose to set \texttt{prev[4][5]} to \texttt{UP}, that would indicate that the algorism should choose the result for the subproblem \texttt{[a][, [a][b} by deleting the character at index 4 of string 1. This is not possible in this case, but you should convince yourself about what each entry in \texttt{prev} means. In general, when an entry \texttt{prev[i][j]} is \texttt{DIAGONAL}, it means the tails of both input strings should be kept during editting. If it is either of the other two, which corrresponds to horizontal or vertial moves, that means the algorism has to delete (or add) one of the tails of the two strings.
  \item Moving right from its left neighbor. The analysis above applies similarly here. 
  \item Moving from the immediate topleft entry, which is \texttt{[i][j]}'s immediate previous diagonal neighbor. This means neither of the two strings' tails should be editted. 
\end{itemize}
The table \texttt{f[][]} and \texttt{prev[][]} all refers to decisions that a traditional Edit Distance algorism would make. The third table \texttt{good[][]} on the other hand, means that it is possible to reach this entry without breaking any blocks as defined by enclosing pairings. Please refer to earlier parts of this section about how blocks are generated.\\

We won't bother you with a detailed step-by-step analysis of the algorithm, and will instead focus on being to the point here. The \textbf{loop invariant} here is:\\
At each entry \texttt{good[i][j]} is \texttt{true} iff there is a way of reaching this entry without breaking any blocks, or pairs of brackets.\\

There are certain points that we should address here:
\begin{itemize}
  \item What does it mean to break a block? that means for the subproblem corresponding to \texttt{[i][j]}, this entry's solution's corresponding editting can't be done without, for a certain pair of brackets, dropping one half in one input string's editting, while keeping both halves in another input string's output editting. That is to say, we require that for each pair of brackets, the two halves of the pair must either be both dropped in a subsolution, or be both preserved in a subsolution. Such an observation helps achieve what we set out to implement in the first place: fixing ignorance of brackets pairing.
  \item This invariant does not address the table \texttt{f[][]} and the table \texttt{prev[][]}. Again, these two tables store solutions that comes from dynamic decisions made in the same way as any bottom-up Dynamic Programming algorism. 
\end{itemize}








\begin{thebibliography}{9}
%The \bibitem is to start a new reference.  Ensure that the cite_key is
%unique.  You don't need to put each element on a new line, but I did
%simply for readability.
    \bibitem{minhash}
      \href{https://github.com/codelibs/minhash}{codelibs/minhash: A third-party Java-based libary  for b-bit MinHash algorism}


\end{thebibliography} %Must end the environment


\end{document}  %End of document.