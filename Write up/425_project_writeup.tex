% personal latex template

% vegito2002@gmail.com
\documentclass{article}
\usepackage{times}
\usepackage{mathptmx}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage[letterpaper, margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{lipsum}
\usepackage{courier}
% \usepackage{tabularx}
\usepackage[export]{adjustbox}
% \usepackage[landscape]{pdfpages}
\usepackage{enumitem}
\usepackage{spreadtab}
% \usepackage{enumerate}


\graphicspath{ {images/} }

\usepackage[dvipsnames]{xcolor}  %% Allow color names
\lstset
{ %Formatting for code in appendix
  belowcaptionskip=1\baselineskip,
  xleftmargin=\parindent,
  language=Java,   %% Change this to whatever you write in
  breaklines=true, %% Wrap long lines
  basicstyle=\ttfamily,
  % numbers=left,
  % stepnumber=1,
  commentstyle=\itshape\color{Gray},
  stringstyle=\color{Orange},
  keywordstyle=\bfseries\color{WildStrawberry},
  identifierstyle=\color{Blue},
}
\usepackage{titlesec}
\usepackage{amssymb}
\newenvironment{claim}[1]{\par\noindent\underline{Claim:}\space#1}{}
\newenvironment{claimproof}[1]{\par\noindent\underline{Proof:}\space#1}{\leavevmode\unskip\penalty9999 \hbox{}\nobreak\hfill\quad\hbox{$\blacksquare$}}

\setcounter{secnumdepth}{4}

\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\begin{document}

% Article top matter
\title{\textsc{EN 600.425 Declarative Methods \\ - Term Project Writeup}\\ \textbf{\textsc{Better } \texttt{diff}}} %\LaTeX is a macro for printing the Latex logo
\author{Guoye Zhang, Qiang Zhang\\
        % \texttt{Hopkins ID: 92CC3E}
        }  %\texttt formats the text to a typewriter style font
\date{\today}  %\today is replaced with the current date
\maketitle

\section{Introduction}
The utility \texttt{diff} is commonly used in all scenarios, whether for programming purpose or in general text editing circumstances. The website Github integrated \texttt{diff} into their version control system, facilitating ubiquitous knowledge of the utility. This legacy utility is based on the renowned \textit{Edit Distance} algorithm, which in essence is a Dynamic Programming algorithm. \\

Aside from the application domain of version control, \texttt{diff}'s algorithm in itself is interesting and instructive enough for most computer science students to delve into. In general sense, the concepts of finding similar text and displaying minimum edit distance can be embodied in various domains and categories of applications. Our project aims at extending \texttt{diff} to provide firstly the feature of multi-file editting source referencing, accompanied with visualization, that can display the chain of editting among more than two files placed in the same folder, together with a better algorithm that fixes a certain scenario where the normal \texttt{diff}'s Edit Distance algorithm would perform suboptimally, which is a case we already described in the proposal.\\

\subsection{Algorithmic Optimization}
As a reminder, recall the scenario where normal \texttt{diff} would perform suboptimally. In this code snippet:\\
\begin{lstlisting}
   for(int i=0; i<10; i++) {
       System.out.println("First line");
   }
   for(int i=0; i<10; i++) {
       System.out.println("Second line");
   }
   for(int i=0; i<10; i++) {
       System.out.println("Third line");
   }
\end{lstlisting}
from which we will delete the second \texttt{for} block. And if we use the traditional \texttt{diff} on the old and new versions of this snippet, we would get:\\
\begin{lstlisting}
   for(int i=0; i<10; i++) {
       System.out.println("First line");
   }
   for(int i=0; i<10; i++) {
 -     System.out.println("Second line");
 - }
 - for(int i=0; i<10; i++) {
       System.out.println("Third line");
   }
\end{lstlisting}
Instead of what would be expecting as follows:
\begin{lstlisting}
   for(int i=0; i<10; i++) {
       System.out.println("First line");
   }
 - for(int i=0; i<10; i++) {
 -     System.out.println("Second line");
 - }
   for(int i=0; i<10; i++) {
       System.out.println("Third line");
   }
\end{lstlisting}
This case is fixd with our improved version of \texttt{diff} algorithm, which we shall call by \texttt{MDiff} in the rest of this document. In fact, there are much more scenarios where the traditional \texttt{diff} algorithm would disappoint you. For example, consider the instance of comparison below (results are hand-generalized from Github's webpage highlighting):
\begin{lstlisting}
<a><b>
 ----

<b><a>
 ++++
\end{lstlisting}
The notations used here should be self-explanatory. When comparing the two strings of \texttt{<a><b>} and \texttt{<b><a>}, traditional \texttt{diff} would return the results as shown above, which means, in a 0-based indexing convention, deleting the 1-4 of the first string, and adding the 4 characters at index 1-4 of the second string. But this answer of editting distance is clearly suboptimal. The optimal solution we expect would be:
\begin{lstlisting}
<a><b>
 -  -

<b><a>
 +  +
\end{lstlisting}
which is the answer that \texttt{MDiff} would return.

\subsection{Multi-file Referencing}
In this part, we extended \texttt{diff} to another domain of applicaiton of interest. To most eyes, \texttt{diff} is generally used to comparing the editting distance between two files. It is a utility used widely in use. Indeed, it is a utility, in that it does a job well, but it is not typically tailored for any domain. We implemented an application that embodies \texttt{MDiff} in its core, but meanwhile provides far more convenient and appleasing functionalities. \\

For oft, we are interested not only to know the difference between two text files. Rather, we want to be able to look at some paragraph of this text file, and find out from which other paragraph in other file this paragraph derives. Text reusing is so common nowadays that this is a feature of no trivial productivity significance. In fact, to fullfill such a task, of finding the predecessor of a paragraph in this text file, most people would resort to nothing better than a brute-force file-by-file \textit{Open\&Search} routine. \\

To implement this feature, the optimized algorithm of \texttt{MDiff} alone is not quite enough. In practical scale, even comparing only two files with a \texttt{diff}-based algorithm can be undesirably slow. Not to mention that we are trying to determine edit chains between multiple files. For the application to be fast enough to be useful in practice, certain techniques are used to structure the implementation of its functionality.\\

The use case we are trying to address here is a scenario where the folder contains, rather than multiple files, multiple versions of a file. For example, \texttt{file1} could be the original file of an article in craft. Then after certain modifications, \texttt{file2} results. In the end, the folder contains multiple files, each pair of which, albeit being different, shares an overall similarity larger than 50\%. Aside from that, we make the below assumptions:
\begin{enumerate}
  \item File name indicate each file's last-modified-by time in an increasing order. Thus if there is a file $i$ and a file $j$ with $i<j$, we can convince ourselves that file $i$ is lastly modified earlier than file $j$ and file $j$ is thus possile a successor of $i$: meaning we should include file $i$'s texts when we try to search for the predecessor of any text paragraph in file $j$. To be honest, this modelling is not perfectly accurate. For example, in the case below:\\
  \includegraphics[scale=0.3,center]{pic1.png}

  File 5 is modified later than file 4 (since 5 is larger than 4, and thus file 5 has a later last modification timestamp), but file 5 actually should not consider file 4 as one of its predecessor, because file 5 comes from modifications of file 2, and is on a editting path branch disjoint from that of file 2. 

  But overall, our approach should work fine. 
  \item The author of the files knows to seperate each section, or paragraph of his files by an empty line. Like:
  \begin{lstlisting}
  <paragraph1>

  <paragraph2>

  <paragraph3>
  \end{lstlisting}
  This is similar to how most Latex users format their documents. 
\end{enumerate}
When we open a certain file $i$, we want to be able to know:
\begin{enumerate}
  \item \textbf{Objective 1}: Amongst all the paragraphs of all files in this folder, which paragraph is most likely to be the direct predecessor of this paragraph? Or, which paragraph is most likely to be the direct source of modification for this paragraph?
  \item \textbf{Objective 2}: After finding the most likely predecessor of this paragraph, what are the minimum amount of edits required to change from the predecessor paragraph to the paragraph under inspection?
\end{enumerate}

Objective 2 as we described in the last subsection, is addressed by an optimized version of \texttt{diff} algorithm, which we call \texttt{MDiff}. Objective 1's on the other hand, is key to speeding up the application to a speed suitable for real-life utilization. \\

By matching texts in the unit of paragraph first, we largely reduced the computational effort required. Yet this scheme does not violate any practical editting convention to render the application infutile. Normally, when a user edits a file, the edits, however many there are at a time, can be each bucketted into its own paragraph. By matching paragraphs first, we limit the scope to apply \texttt{MDiff} on to only a paragraph a time.  This is analogous to an idea in 3D game designing that you don't have to render the entire 3D scene and maintain it at all time. You just have to render as large as the player's camera can capture and only when the camera does captures it. This optimization can reduce the computational cost of the application by a factor as large as several hundreds inpractice. \\

The key idea behind implementing Objective 1, and the paragraph matching explained above, is determine textual similarities. There is a well-established technique called Min-hash which is used to calculate a text document's signature, which can in turn be used to compare with another document's signature to determine the similarity between the two documents. Of course, we here are looking at the similarity between two documents rather than two paragraphs. We used a third-party library \cite{minhash} which can return the similarity of two text strings based on the Min-hash algorithm. \\

There are more subtlties to be clarified in this scheme. But we are leaving further elaboration for later part of this document. 

\subsection{Running Instruction}
By this point, enough information is provided to understand what this project hopes to deliver. In this section, we provide step by step instructions so that you can run the application now and see the results before going further. More elaborations follows.

\section{First Step: Predecessor Matching}
Definition first: \textbf{Predecessor Matching} refers to the process of finding, for each paragraph $p$ in each file $file_p$, amongst all the paragraphs that are contained in files with a lastly modification timestamp (which is assumed to be indicated by the filename number's value ordering) smaller than $file_p$. The concept of similarity is calculated by comparison of signature which is calculated by \textbf{Minhash}.
\subsection{Modelling}
As described in the previous section, our first goal is to be able to inspect a certain file $i$ in the folder, and immediately locate the most similar paragraph amongst all files in the folder, under assumptions:
\begin{enumerate}
  \item File name indicate each file's last-modified-by time in an increasing order.
  \item The author of the files knows to seperate each section, or paragraph of his files by an empty line. 
\end{enumerate}

The second assumption is established so that there is a valid way to define the notion of ancestry. If we treat an entire document as one single paragraph, then there is no point in saying \textit{finding the predecessor of this entire document}. Because in practice, most modifications between files are minor and of comparable degree, which means different successors of the same predecessor document may end up looking very much alike. Even though we devise an algorithm to locate such an predecessor document for the document being inspected, the output is most likely to be inaccurate and uninformative. \\

After dividing a document into paragraphs, the notion of ancestry and the concept of reusing now makes sense. Think it this way: when you write code, if you say \textit{reuse}, you usually refers to reusing a part of a code file, usually a function, or block. But in the case you want to reuse the code file in its entirety, you just \texttt{import} or \texttt{include} it. Such file-wise reusing operations would normally indicate the source of reusing directly and an dedicated algorithm to solve the ancestry relationship would be unnecessary. The same analysis applies to the case of general text files. We are only interested in finding the predecessor of a snippet of a text file, which is a reused part. We conveniently define such a concept of reused part as a paragraph. There can be other choices of delimitation of reused parts, but obsession over this definition is moot per se. \\

Now, to find the most likely predecessor of a paragraph, is to find a paragraph that:
\begin{enumerate}
  \item is contained in a file that is lastly modified earlier than the file that contains the paragraph under inspection.
  \item shares, amongst all paragraphs that satisfies the previous condition, a highest similarity with the paragraph under inspection.
  \item owns a similarity with the paragraph that satisfies the previous condition that is higher than a lower threshold.
\end{enumerate}
And to find such a paragraph that satisfies the above three conditions, we use the theory of textual similarity. \\

\subsection{Texutual Similarity and Textual Similarity}
Since this is only a subroutine we resort to in this project, rather than the project itself's primary focus, the introduction here is brief. Minhash is a hashing scheme that can hash each string or piece of text to a value that is necessarily short but informative enough to capture the uniqueness of the text. This value is called the \texttt{signagure} of this text. Minhash is designed to be able to hash similar texts to similar signatures. And by a corresponding comparison function of two texts' respective signature, the two texts' similarity can be determined.

\subsection{Implementation}
Back to the implementation of the application. In particular, we implement the process as follows:
\begin{enumerate}
  \item Read in all files in the folder in the order of increasing lastly-modification time, which is determined by the filenames. Create two string arrays, one to store the filenames of all the files in question and one to store each file's content of all files. 
  \item For each content string of the file content array, break up the content string into an string array of storing this file's lines. By doing this, we have a 2-dimensional array of \texttt{filelines[m][n]} where \texttt{m} stands for the number of files involved, and \texttt{n} stands for each file's number of lines in its content. Incidentally, we trim out the whitespaces at the head and tail of each line. 
  \item Using this 2-dimensional array \texttt{filelines[m][n]}, we scan all the lines of all files in the order of an intuitive 2-dimensional iterative order: 
  \begin{lstlisting}
  for (int i = 1 .. m) {
    for (int j = 1 .. n) {
      <process>
    }
  }
  \end{lstlisting}
  In this scanning, we break up all the lines into paragraphs by the delimiter of \textit{emptyline} as mentioned before. For each paragraph, we iterate through all paragraphs discovered before it, and find the one paragraph with the highest similarity to it, which has to be above 80\%. We determine this paragraph as the \textbf{predecessor} of current iteration's paragraph. Relevant information are all stored. 
  \item Once we know the predecessor for each of all paragraphs of all files in the folder, we also maintain the edit distance produced by the improved \texttt{MDiff} algorithm with each paragraph. More specifically, this edit distance is calculated against each paragraph's predecessor with itself. By now, we have all the information we need to implement the application layer features in the future. For each paragraph, the information, in summary, typically consists of:
  \begin{itemize}
    \item The filename of the file that contains this paragraph. Note that we are being a little simplistic here: we assume that each file has a filename in the format of $i.<extension>\ \forall i$. This assumption does not harm the generality of application for the project and can be easily extended if necessary.
    \item The start and ending line numbers of this paragraph in the file that contains it. With these line numbers and the filename stored in the above entry, the paragraph itself now can be uniquely located.
    \item A pointer to the paragraph's \textbf{predecessor}, which is determined by a concept of \textit{maximum similarity so far} as described above.
    \item Annotation to represent the result of running \texttt{MDiff} with this paragraph's predecessor as the first argument and this paragraph itself as the second argument. Note that although we are trying to accomplish something that looks like multi-file \texttt{diff}ing here, the \texttt{MDiff} algorithm itself only takes two strings at a time. 

    The annotation consists of three parts. We will illustrate each part's meaning with this example's help:
    \begin{lstlisting}
<a><b>
 -  -

<b><a>
 +  +
    \end{lstlisting}
    \begin{itemize}
      \item The \texttt{boolean same} value, which is \texttt{true} if the two string arguments are the same, which means the edit distance is 0. In the case of the example shown here, this flag should be \texttt{false}.
      \item The \texttt{boolean[] delete} flag array. The explanation is left to below.
      \item The \texttt{boolean[] add} flag array. Remind yourself that although we are introducing the information maintained for each paragraph, the \texttt{delete} and \texttt{add} flag arrays actually apply to this paragraph's predecessor and this paragraph itself. Since for each paragraph, its predecessor can be uniquely identified.

      The \texttt{delete} boolean flag array corresponds to the predecessor string, which is \texttt{<a><b>} in this case. The flags in this array indicates whether each character in the string would be kept so that the predecessor string could be editted into the target successor string with minimum editting distance. In particular, each flag is false if the corresponding character in this paragraph's predecessor paragraph should be deleted in min-distance editting. In this case, the \texttt{delete} array should be \texttt{\{true,false,true,true,false,true\}}. Note that this information is stored with the paragraph \texttt{<b><a>}, rather than the paragraph (string) \texttt{<a><b>}.

      Similarly, \texttt{add} boolean flag array corresponds to the new, or successor string/paragraph of the pair. If \texttt{add[i]} is true, then the character at 0-based position $i$ will be be seen as an uneditted character(certainly not deleted, yet is not also added to the new paragraph) when trying to edit this paragraph's predecessor into this paragraph itself with minimum distance. If \texttt{add[i]} is false, then the character at position $i$ will be considered newly added during the min-distance editting. In this example, the \texttt{add} array, of a value \texttt{\{true,false,true,true,false,true\}}, should be maintained with the paragraph \texttt{<b><a>}.
    \end{itemize}
  \end{itemize}
\end{enumerate}

This section is intended to focus on matching each paragraph with its predecessor, which is located by the \textit{most similar paragraph so far} scheme as decribed above. In the explanation, we assumed that we already have the utility of \texttt{MDiff} and includes its result for each paragraph together with the result of \textbf{Predecessor Matching}. Note that with these information stored, we can easily implement any visualization we want. We did implement a HTML-based visualization, but discussion shall be omitted. \\

Although this section is named the \textbf{First Step}, we essentially introduced the big picture architecture of the project. With the skeleton built out, all that left is to fill in the muscles, especially a powerful one. The \textbf{Predecessor Matching} scheme based on \textbf{Minhash} provides all the inter-paragraph information we need. To get the intra-paragraph information, we need an algorithm to compare a paragraph itself to its predecessor paragraph. And the introduction of this algorithm is developed next.

\section{Better \texttt{diff}: \texttt{MDiff}}
Our optimization of the original \texttt{diff}, or Edit Distance algorithm, focuses on fixing Edit Distance algorism's ignorance of \textbf{brackets pairing}. Note that although we use the term \textit{brackets} here, we actually refer to parentheses, brackets, braces in general. This naming convention would apply for the rest of this document. \\

In section 1 of \textit{Introduction}, we gave several examples where Edit Distance algorithm won't be able to find an optimal, or even reasonable result. In our improved algorithm of \texttt{MDiff}, we are able to deal with not only ignorance of brackets pairing, which in practice usually comes in the form of an editting that deleted or added only part of a paring of brackets, but also Edit Distance's ignorance of quote pairing. Special scenarios like escaping character are also considered.

\subsection{Failed Attemp 1 with ZIMPL}
This problem appears to us in the beginning as difficult to solve with Dynamic Programming which is adopted by the original Edit Distance algorithm. We decided to put what we learned in this course in practice and give ZIMPL a try. \\

The files associated with this attempt are all put in the folder \textit{Deprecated} which is located at the root level:
\begin{itemize}
  \item \texttt{Script.java} is a trivial Java file to write input \texttt{txt} files for the program. \texttt{out.txt} is the temporary file of the Java file's output.
  \item \texttt{old.txt} and \texttt{new.txt} are files to represent the old string and new string as the input of the program. Instead of expressing the inputs as a string, we expressed them as an array of integers. The encoding and decoding between should be straightforward.
  \item \texttt{zimpl\_attemp1.zpl} is the program file. I would not recommend running it since it unfinished and erroneous in nature. 
\end{itemize}

The approach we took in this attempt is to encode each input string's each character as an integer. Then we try to use ZIMPL to decide a binary variable for such a digit. This binary variable plays a role similar to each \texttt{delete} and \texttt{add} boolean flag we used in the java program. \\

The process should be easier to explain with an example. Note that in this attempt we have not come so far to addressing the ignorance of bracket pairing yet. Implementing Edit Distance alone seems difficult enough. With this simple example, we begin the discussion:
\begin{lstlisting}
Old String:
#index, number
1,1
2,2
3,3
4,4
5,5

New String:
#index, number
1,1
2,2
3,4
4,3
5,5
\end{lstlisting}
The input string is stored in variables \texttt{old[M]} and the output string is stored in variables \texttt{new[N]}. For \texttt{M}, we also have the binary annotation variable \texttt{delete[M]}, and similarly \texttt{add[N]} for \texttt{N}. Note that the value of the binary variables are the opposite of the \texttt{delete} and \texttt{add} Java boolean flags mentioned above. Here, \texttt{delete[m]} is 1 iff the digit $m$ of the input string (digit array) should be deleted in a min-distance editting. Similarly, i\texttt{add[n]} should be 1 iff the digit $n$ should be seen as an added digit in a min-distance editting. \\

With such definition, we derive another two variable definitions: \texttt{after\_delete[M]} and \texttt{before\_add[N]}.  \texttt{after\_delete[M]} is essentially \texttt{old[M]} after a mapping function being applied, which sets \texttt{after\_delete[m]} to 0 if \texttt{delete[m]} is 1 and to \texttt{old[m]} otherwise. \texttt{before\_add[N]} is defined in a similar way. It is intuitive to add a minimizing objective function, where the coefficients of \texttt{delete[M]} and \texttt{add[N]} are all positive. All that's left to now is to set up constraints. \\

Note, to express that the editting determined by \texttt{delete[M]} and \texttt{add[N]} is a valid editting, which measn applying the indicated editting would correctly tranform \texttt{old[M]} to \texttt{new[N]}. Such a notion of valid editting shall be implemented with a constraint, which we might as well call \textbf{mapped equality} that could determine the following two strings equal (these two strings do conform to the example inputs listed above):
\begin{lstlisting}
after_delete[M]:
1,2,0,4,5

before_add[N]
1,2,4,0,5
\end{lstlisting}
We first considered removing zeroes, which shortly turned out infeasible if we have a general case of \texttt{1,2,0,0,0,0,0,3,4} to process. We can't express the idea of a while-loop in ZIMPL, and it is infeasible to remove consecutive zeroes of arbitrary length. \\

Even more, at this point, we realized that trying to further transforming \texttt{after\_delete[M]} and \texttt{before\_add[N]} is very hard. We then turned our mind to tuning the objective function with some soft constraints to lure the solver to the correct solution. These attempts all failed with some input cases so I will just briefly summarize here:
\begin{itemize}
  \item Objective function: the terms
  \begin{lstlisting}
  sum <m> in M: delete[m] + sum <n> in N: add[n]
  \end{lstlisting}
   are fixed in all the approaches below. 
  \item Hard constraint: sum of \texttt{after\_delete[M]}  and \texttt{before\_add[N]} should be equal. This is only a necessary constraint to express the mapped equality, but not enough to be sufficient.
  \item Hard constraint: the number of zeroes in each of \texttt{after\_delete[M]} and \texttt{before\_add[N]} is the same. Again, this is also only a necessary constraint. \\

  And the below appraoches are mostly inspired by analysis of concret input cases:
  \begin{itemize}
    \item Approach 1: adding 
    \begin{lstlisting}
    - vabs(sum <m> in M: after_delete[m] * m - sum <n> in N: before_add[n] * n) / 2
    \end{lstlisting}
     to the objective function. However we tune the weight of this term, the solver would always be too eager to increase the number of deletions and additions to maximize its gain on this term.
    \item Approach 2: derive \texttt{difference1[M]} for \texttt{after_delete[M]} with \texttt{difference1[m]} standing for \texttt{after_delete[m-1]} minus \texttt{after_delete[m]}. \texttt{difference2[N]} is defined similarly based on \texttt{before_add[N]}. Then we require that:
    \begin{lstlisting}
vabs(difference1[m]) == sum <n> in N: vabs(difference2[n])
    \end{lstlisting}
    We did know this constraint can't be enough. Though seems tempting, the solver, for various input cases, ends up finding clever roundabouts satisfying this constraint. 
    \item Approach 3: \texttt{difference} variables defined as above. But now we add 
    \begin{lstlisting}
+ vabs(sum <m> in M: vabs(difference1[m])*m - sum <n> in N: vabs(difference2[n])*n)
    \end{lstlisting}
    To the objective function.
  \end{itemize}
  Other trivial approaches are tried out as well, and do not merit mentioning here. 
\end{itemize}


\subsection{Suboptimal Attemp 2 with ZIMPL}












\begin{thebibliography}{9}
%The \bibitem is to start a new reference.  Ensure that the cite_key is
%unique.  You don't need to put each element on a new line, but I did
%simply for readability.
    \bibitem{minhash}
      \href{https://github.com/codelibs/minhash}{codelibs/minhash: A third-party Java-based libary  for b-bit MinHash algorism}


\end{thebibliography} %Must end the environment


\end{document}  %End of document.